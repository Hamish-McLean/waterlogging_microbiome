---
title: "Waterlogging microbiome analysis"
author: "Hamish McLean"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: cerulean
    highlight: tango
params:
  pipeline: "DADA2"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(viewer = NULL)
options(kableExtra_view_html = interactive())
if (!exists("params")) params <- list(pipeline = "DADA2")
```

```{r libraries}

library(buildmer)
library(car)
library(data.table)
library(DESeq2)
library(dplyr)
library(emmeans)
library(ggpubr)
library(gridExtra)
library(here)
library(kableExtra)
library(lme4)
library(lmPerm)
library(performance)
library(permutes)
library(see)
library(vegan)
library(viridis)

```

```{r functions}

here <- here::here()

FUNC_DIR <- here("functions")

source(file.path(FUNC_DIR, "loadme.R"))
source(file.path(FUNC_DIR, "metabarcoding.R"))
source(file.path(FUNC_DIR, "metafuncs.R"))
source(file.path(FUNC_DIR, "rarefaction.R"))

```

```{r constants}

DATA_DIR    <- normalizePath(here("..", "Data"))
FIGURES_DIR <- here("figures")

# Bioinformatics pipeline (defaults to DADA2)
# This should be set in the YAML header or passed as a parameter
PIPELINE <- params$pipeline # DADA2 or USEARCH
ASV_FILTER  <- 0.001 # ASV filter for removing low abundance ASVs
READ_FILTER <- 0.05 # Read count filter for rarefaction
TAX_CONF    <- 0.65 # Confidence threshold for taxonomic rank assignment

# Colour blind palette
cbPalette <- c(
  "#000000", "#E69F00", "#56B4E9", "#009E73", 
  "#F0E442", "#0072B2", "#D55E00", "#CC79A7"
)

# Model designs
# Timepoint model for E1
# formula_t <- y ~ treatment * timepoint + (1 | plot) + (1 | block)
T_DESIGN <- y ~ treatment * timepoint + (1 | block)

# Experiment model without timepoint 2
E_DESIGN <- y ~ treatment * experiment + (1 | block / experiment)

```

## Load data

```{r load data}

# File extensions based on pipeline
if(PIPELINE == "DADA2") {
  asv_ext <- ".asv_table_filtered.txt"
  fun_tax <- "FUN.sintax.taxa"
  bac_tax <- "BAC.sintax.taxa"
} else if(PIPELINE == "USEARCH") {
  asv_ext <- ".zotu_table.txt"
  fun_tax <- "zFUN.sintax.taxa"
  bac_tax <- "zBAC.sintax.taxa"
} else {
  stop("Pipeline not recognised")
}

# Load fungal data

FUN <- loadData(
  here(DATA_DIR, PIPELINE, paste0("FUN", asv_ext)),
  here(DATA_DIR, "metadata.txt"),
  here(DATA_DIR, PIPELINE, fun_tax),
  tax_conf = TAX_CONF,
  RHB = "FUN"
)

# Load bacterial data

BAC <- loadData(
  here(DATA_DIR, PIPELINE, paste0("BAC", asv_ext)),
  here(DATA_DIR, "metadata.txt"),
  here(DATA_DIR, PIPELINE, bac_tax),
  tax_conf = TAX_CONF,
  RHB = "BAC"
)

# Remove ".raw" from the end of the colnames of the countData
colnames(FUN$countData) <- gsub("\\.raw$", "", colnames(FUN$countData))
colnames(BAC$countData) <- gsub("\\.raw$", "", colnames(BAC$countData))

# Add a new column to colData that combines experiment and timepoint
FUN$colData$exp_tp <- paste(FUN$colData$experiment, FUN$colData$timepoint, sep = "|")
BAC$colData$exp_tp <- paste(BAC$colData$experiment, BAC$colData$timepoint, sep = "|")

# Convert all columns to factors
FUN$colData[] <- lapply(FUN$colData, as.factor)
BAC$colData[] <- lapply(BAC$colData, as.factor)

```

## Filter data

### Filter taxa

Plantae taxa are filtered from fungal `taxData`.
Chloroplast and Eukaryote  taxa are filtered from bacterial `taxData`.
Corresponding ASVs are removed from `countData`.

```{r filter taxa}

# Fungi: Plantae ASVs
cat(
  "Fungi:\n",
  " - Total ASVs:", nrow(FUN$taxData), "\n",
  " - Plantae ASVs:", length(grep("Plantae", FUN$taxData$kingdom)), "\n\n"
)

# Filter Plantae ASVs
filt <- rownames(FUN$taxData[grep("Plantae", FUN$taxData$kingdom), ])

if(length(filt) == 0) {
  cat("No fungal ASVs to remove\n")
} else {
  cat("Fungi: removing", length(filt), "ASVs\n")
  FUN$taxData <- FUN$taxData[!rownames(FUN$taxData) %in% filt, ]
  FUN$countData <- FUN$countData[!rownames(FUN$countData) %in% filt, ]
}

# Bacteria: Chloroplast (Streptophyta) and Eukaryote ASVs
cat(
  "Bacteria:\n",
  " - Total ASVs:", nrow(BAC$taxData), "\n",
  " - Chloroplast ASVs:", nrow(BAC$taxData[
    grepl("Streptophyta", BAC$taxData$genus) & 
    as.numeric(BAC$taxData$g_conf) >= TAX_CONF,
  ]), "\n",
  " - Eukaryote ASVs:", length(grep("Eukaryota", BAC$taxData$kingdom)), "\n\n"
)

# Filter Chloroplast and Eukaryote ASVs
filt <- rownames(
  BAC$taxData[
    grepl("Streptophyta", BAC$taxData$genus) & 
    as.numeric(BAC$taxData$g_conf) >= TAX_CONF,
  ]
)

filt <- unique(c(filt, rownames(BAC$taxData[grep("Eukaryota", BAC$taxData$kingdom), ])))

if(length(filt) == 0) {
  cat("No Bacterial ASVs to remove\n")
} else {
  cat("Bacteria: removing", length(filt), "ASVs\n")
  BAC$taxData   <- BAC$taxData[!rownames(BAC$taxData) %in% filt, ]
  BAC$countData <- BAC$countData[!rownames(BAC$countData) %in% filt, ]
}

```

### Rarefaction

Remove samples with read count below `r READ_FILTER * 100` % of median.

```{r rarefaction}

rare_fun <- gfunc(FUN$countData, FUN$colData, "Fungi")

rare_bac <- gfunc(BAC$countData, BAC$colData, "Bacteria")

rarefaction_plots <- grid.arrange(
  rare_bac, rare_fun,
  # left = textGrob(label = expression("log"[10] * " aligned sequences"), rot = 90),
  bottom = "ASV count", nrow = 2
)

ggsave(filename = "rarefaction_plots.png", plot = rarefaction_plots, path = FIGURES_DIR)

rarefaction_plots

# Fungi
med <- median(colSums(FUN$countData))
filt <- !colSums(FUN$countData) > med * READ_FILTER
cat("Fungi: ", sum(filt), "sample(s) with <", READ_FILTER * 100, "% of median reads\n\n")

# Bacteria
med <- median(colSums(BAC$countData))
filt <- !colSums(BAC$countData) > med * READ_FILTER
cat("Bacteria: ", sum(filt), "sample(s) with <", READ_FILTER * 100, "% of median reads\n\n")

```

### Filter ASVs by read count

Remove ASVs with less than `r ASV_FILTER * 100` % of total reads across all samples.

```{r asv propotions}

asv_propotions <- function(countData, proportion){
  i <- sum(countData)
  y <- rowSums(countData)
  y <- y[order(y, decreasing = T)]
  asvs <- length(y[(cumsum(y) / i <= proportion)])
  return(asvs)
}

proportions <- c(0.5, 0.9, 0.99, 0.999, 1)

top_asvs <- data.table(
  "proportion" = proportions,
  "Fungi" = lapply(proportions, function(x) asv_propotions(FUN$countData, x)),
  "Bacteria" = lapply(proportions, function(x) asv_propotions(BAC$countData, x))
)

top_asvs %>%
  kbl() %>%
  kable_styling("striped", full_width = F)

```

Keep only ASVs with at least 10 reads in at least 2 samples.

```{r filter asvs}

filter_asvs <- function(countData, min_count = 10, min_samples = 2) {
  keep <- rowSums(countData >= min_count) >= min_samples
  names(keep[keep])
}

# Fungi
# keep <- filter_otus(FUN$countData, ASV_FILTER)
keep <- filter_asvs(FUN$countData)
cat(
  "Fungi:\n", 
  " - total ASVs:", nrow(FUN$countData), "\n",
  " - removing", nrow(FUN$countData) - length(keep), "ASVs\n",
  " - remaining ASVs:", length(keep), "\n\n"
)

FUN$taxData <- FUN$taxData[rownames(FUN$taxData) %in% keep,]
FUN$countData <- FUN$countData[rownames(FUN$countData) %in% keep,]

# Bacteria
# keep <-  filter_asvs(BAC$countData, ASV_FILTER)
keep <- filter_asvs(BAC$countData)
cat(
  "Bacteria:\n",
  " - total ASVs:", nrow(BAC$countData), "\n",
  " - removing", nrow(BAC$countData) - length(keep), "ASVs\n",
  " - remaining ASVs:", length(keep), "\n\n"
)

BAC$taxData <- BAC$taxData[rownames(BAC$taxData) %in% keep,]
BAC$countData <- BAC$countData[rownames(BAC$countData) %in% keep,]

```

## Absolute abundance normalisation

ASV normalisation is performed using qPCR theoretical copy number data.
Copy number is calculated per mg of root sample from the qPCR data.

### Prepare qPCR abundance data

```{r qPCR abundance}

abundance <- read.csv(here(DATA_DIR, "abundance.csv"))

FUN$abundance <- subset(abundance, Target == "ITS")
BAC$abundance <- subset(abundance, Target == "16S")

rownames(FUN$abundance) <- FUN$abundance$Sample
rownames(BAC$abundance) <- BAC$abundance$Sample

# Add `copy_number` to colData from abundance data `TCN_mg`
FUN$colData$copy_number <- FUN$abundance[rownames(FUN$colData), "TCN_mg"]
BAC$colData$copy_number <- BAC$abundance[rownames(BAC$colData), "TCN_mg"]

FUN$colData$log10_copy_number <- log10(FUN$colData$copy_number + 1)
BAC$colData$log10_copy_number <- log10(BAC$colData$copy_number + 1)

```

## Create DESeq objects

```{r DESeq}

# Make sure countData and colData still match, if they do, create DESeq objects
if(identical(colnames(FUN$countData), rownames(FUN$colData))) {
  # Create DESeq object
  FUN$dds <- DESeqDataSetFromMatrix(
    countData = FUN$countData,
    colData = FUN$colData,
    design = ~ 1
  )
  print("FUN DESeq object created")
} else {
  stop("FUN countData and colData do not match")
}

if(identical(colnames(BAC$countData), rownames(BAC$colData))) {
  # Create DESeq object
  BAC$dds <- DESeqDataSetFromMatrix(
    countData = BAC$countData,
    colData = BAC$colData,
    design = ~ 1
  )
  print("BAC DESeq object created")
} else {
  stop("BAC countData and colData do not match")
}

```

## Abundance normalisation

Absolute abundance normalisation using DESeq2 size factors.

Values are centred around the mean of the copy number.

```{r normalisation}
# Normalise count data using DESeq2 size factors

FUN$dds$sizeFactor <- FUN$dds$copy_number / mean(FUN$dds$copy_number)
BAC$dds$sizeFactor <- BAC$dds$copy_number / mean(BAC$dds$copy_number)
```

## ASV and sample summary

### Read and sample summary

```{r read summary}

#' @title Read summary
#' @description Create a summary of the read counts per sample
#' @param dds DESeq2 object
#' @param norm Logical, whether to normalise the counts
#' @return A data.table with the total, mean, median, max and min reads per sample
#'
read_summary <- function(dds, norm = FALSE) {
  countData <- counts(dds, normalize = norm)
  data.table(
    "Total reads" = sum(countData),
    "Mean reads per sample" = mean(colSums(countData)),
    "Median reads per sample" = median(colSums(countData)),
    "Max reads per sample" = max(colSums(countData)),
    "Min reads per sample" = min(colSums(countData))
  )
}

data.table(
  "Metric" = c(
    "Total reads", "Mean reads per sample", "Median reads per sample", 
    "Max reads per sample", "Min reads per sample"
  ),
  "Fungi (Raw)" = unlist(read_summary(FUN$dds, FALSE)),
  "Fungi (Normalized)" = unlist(read_summary(FUN$dds, TRUE)),
  "Bacteria (Raw)" = unlist(read_summary(BAC$dds, FALSE)),
  "Bacteria (Normalized)" = unlist(read_summary(BAC$dds, TRUE))
) %>%
  kbl() %>%
  kable_styling("striped", full_width = F)


```

### ASV summary 

```{r asv summary}

#' @title ASV summary
#' @description Create a summary of the read counts per ASV
#' @param dds DESeq2 object
#' @param norm Logical, whether to normalise the counts
#' @return A data.table with the total, mean, median, max and min reads per ASV
#'
ASV_summary <- function(dds, norm = FALSE) {
  countData <- counts(dds, normalize = norm)
  data.table(
    "Total ASVs" = nrow(countData),
    "Mean reads per ASV" = round(mean(rowSums(countData)), 1),
    "Median reads per ASV" = median(rowSums(countData)),
    "Max reads per ASV" = max(rowSums(countData)),
    "Min reads per ASV" = min(rowSums(countData))
  )
}

data.table(
  "Metric" = c(
    "Total ASVs", "Mean reads per ASV", "Median reads per ASV", 
    "Max reads per ASV", "Min reads per ASV"
  ),
  "Fungi (Raw)" = unlist(ASV_summary(FUN$dds, FALSE)),
  "Fungi (Normalized)" = unlist(ASV_summary(FUN$dds, TRUE)),
  "Bacteria (Raw)" = unlist(ASV_summary(BAC$dds, FALSE)),
  "Bacteria (Normalized)" = round(unlist(ASV_summary(BAC$dds, TRUE)), 2)
) %>%
  kbl() %>%
  kable_styling("striped", full_width = F)


top_asvs <- function(countData, taxData, n = 10) {
  y <- rowSums(countData)
  y <- y[order(y, decreasing = T)]
  xy <- y / sum(y)
  data.frame(
    counts = y[1:n], 
    proportion = xy[1:n], 
    rank = taxData[names(y)[1:n],]$rank
  )
}

top_asvs(FUN$countData, FUN$taxData, n = 10)

top_asvs(counts(BAC$dds, normalize = TRUE), BAC$taxData, n = 10)

```

## Taxonomy Summary

### Taxonomy identifiable

Proportion of ASVs which can be assigned (with the given confidence) at each taxonomic rank.

```{r taxonomy ASVs}

taxonomy_summary <- function(taxData) {
  tx <- copy(taxData)
  setDT(tx)
  cols <- names(taxData)[9:15]
  tx[, (cols) := lapply(.SD, as.numeric), .SDcols = cols]
  
  data.table(
    rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
    "0.8" = round(unlist(lapply(cols, function(col) sum(tx[[col]] >= 0.8) / nrow(tx))), 2),
    "0.65" = round(unlist(lapply(cols, function(col) sum(tx[[col]] >= 0.65) / nrow(tx))), 2),
    "0.5" = round(unlist(lapply(cols, function(col) sum(tx[[col]] >= 0.5) / nrow(tx))), 2)
  )
}

# Fungi

taxonomy_summary(FUN$taxData) %>%
  kbl() %>%
  kable_styling("striped", full_width = F)

# Bacteria

taxonomy_summary(BAC$taxData) %>%
  kbl() %>%
  kable_styling("striped", full_width = F)

```

Proportion of reads which can be assigned to each taxonomic rank.

```{r taxonomy reads}

taxonomy_summary_reads <- function(taxData, dds) {
  tx <-taxData[rownames(dds), ]
  nc <- counts(dds, normalize = T)
  ac <- sum(nc)
  cols <- names(tx)[9:15]
  # tx[, (cols) := lapply(.SD, as.factor), .SDcols = cols]

  data.table(
    rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
    "0.8" = round(unlist(lapply(cols, function(col) sum(nc[which(as.numeric(tx[[col]]) >= 0.8),]) / ac)), 2),
    "0.65" = round(unlist(lapply(cols, function(col) sum(nc[which(as.numeric(tx[[col]]) >= 0.65),]) / ac)), 2),
    "0.5" = round(unlist(lapply(cols, function(col) sum(nc[which(as.numeric(tx[[col]]) >= 0.5),]) / ac)), 2)
  )
}

# Fungi

# taxonomy_summary_reads(FUN$taxData, FUN$dds) %>%
#   kbl() %>%
#   kable_styling("striped", full_width = F)

# Bacteria

taxonomy_summary_reads(BAC$taxData, BAC$dds) %>%
  kbl() %>%
  kable_styling("striped", full_width = F)

```

### Taxonomy plots

```{r taxonomy plots}

```

## Community size

```{r copy number plots}

copy_number_combined <- rbind(
  FUN$colData %>% mutate(type = "Fungi"),
  BAC$colData %>% mutate(type = "Bacteria")
)

copy_number_timepoint <- ggboxplot(
  filter(FUN$colData, experiment == 1), 
  x = "timepoint", y = "log10_copy_number", 
  fill = "weeks",
  xlab = "Timepoint",
  ylab = "log10 Copy number",
  facet.by = c("source")
)

copy_number_experiment <- ggboxplot(
  filter(FUN$colData, timepoint == 1), 
  x = "experiment", y = "log10_copy_number", 
  fill = "weeks",
  xlab = "Experiment",
  ylab = "log10 Copy number",
  facet.by = c("source")
)

ggarrange(
  copy_number_timepoint,
  copy_number_experiment,
  ncol = 1, nrow = 2,
  common.legend = TRUE, legend = "bottom"
)

ggsave(filename = "FUN_copy_number_plots.png", path = FIGURES_DIR)

copy_number_plots

copy_number_timepoint <- ggboxplot(
  filter(BAC$colData, experiment == 1), 
  x = "timepoint", y = "log10_copy_number", 
  fill = "weeks",
  xlab = "Timepoint",
  ylab = "log10 Copy number",
  facet.by = c("source")
)

copy_number_experiment <- ggboxplot(
  filter(BAC$colData, timepoint == 1), 
  x = "experiment", y = "log10_copy_number", 
  fill = "weeks",
  xlab = "Experiment",
  ylab = "log10 Copy number",
  facet.by = c("source")
)

ggarrange(
  copy_number_timepoint,
  copy_number_experiment,
  ncol = 1, nrow = 2,
  common.legend = TRUE, legend = "bottom"
)

ggsave(filename = "BAC_copy_number_plots.png", path = FIGURES_DIR)

```

```{r copy number models}

copy_number_models <- function(data, formula) {
  types <- unique(data$type)
  sources <- unique(data$source)
  for (type in types) {
    data_type <- filter(data, type == type)
    for (src in sources) {
      data_src <- filter(data_type, source == src)
      cat("\n", type, ":", src, "\n", sep = "")
      model <- lmer(update(formula, copy_number ~ .), data_src)
      # check_model(model)
      # print(model)
      summary(model) |> print()
      Anova(model, type = 3) |> print()
    }
  }
}

cat("\nTimepoint:\n")

copy_number_models(filter(copy_number_combined, experiment == 1), T_DESIGN)

cat("\nExperiment:\n")

copy_number_models(filter(copy_number_combined, timepoint == 1), E_DESIGN)

```

## Alpha diversity

### Alpha diversity plots

```{r alpha diversity plots}

# Add a new column to colData that combines experiment and timepoint
FUN$colData$exp_tp <- paste(FUN$colData$experiment, FUN$colData$timepoint, sep = "|")
BAC$colData$exp_tp <- paste(BAC$colData$experiment, BAC$colData$timepoint, sep = "|")

# Root fungi

plot_alpha(
  FUN$countData, FUN$colData[FUN$colData$source == "root", ],
  design = "exp_tp", colour = "weeks",
  measures = c("S.chao1", "Shannon", "Simpson"),
  type = "box"
) + scale_colour_manual(values = cbPalette) + 
  # theme(axis.title.x = element_blank()) +
  ggtitle("Root fungi α-diversity")

ggsave(filename = "root_fungal_alpha.png", path = FIGURES_DIR)

# Soil fungi

plot_alpha(
  FUN$countData, FUN$colData[FUN$colData$source == "soil", ],
  design = "exp_tp", colour = "weeks",
  measures = c("S.chao1", "Shannon", "Simpson"),
  type = "box"
) + scale_colour_manual(values = cbPalette) + 
  # theme(axis.title.x = element_blank()) +
  ggtitle("Soil fungi α-diversity")

ggsave(filename = "soil_fungal_alpha.png", path = FIGURES_DIR)

# Root bacteria

plot_alpha(
  BAC$countData, BAC$colData[BAC$colData$source == "root", ],
  design = "exp_tp", colour = "weeks",
  measures = c("S.chao1", "Shannon", "Simpson"),
  type = "box"
) + scale_colour_manual(values = cbPalette) + 
  # theme(axis.title.x = element_blank()) +
  ggtitle("Root bacteria α-diversity")

ggsave(filename = "root_bacterial_alpha.png", path = FIGURES_DIR)

# Soil bacteria

plot_alpha(
  BAC$countData, BAC$colData[BAC$colData$source == "soil", ],
  design = "exp_tp", colour = "weeks",
  measures = c("S.chao1", "Shannon", "Simpson"),
  type = "box"
) + scale_colour_manual(values = cbPalette) + 
  # theme(axis.title.x = element_blank()) +
  ggtitle("Soil bacteria α-diversity")

ggsave(filename = "soil_bacterial_alpha.png", path = FIGURES_DIR)

```

### Permutation ANOVA on alpha diversity index ranks

```{r alpha diversity anova}

# Alpha diversity data

fun_alpha <- plot_alpha(FUN$countData, FUN$colData, returnData = TRUE)
bac_alpha <- plot_alpha(BAC$countData, BAC$colData, returnData = TRUE)

# Join with metadata
fun_alpha <- fun_alpha[as.data.table(FUN$colData, keep.rownames = "Samples"), on = "Samples"]
bac_alpha <- bac_alpha[as.data.table(BAC$colData, keep.rownames = "Samples"), on = "Samples"]

combined_alpha <- rbind(
  fun_alpha[, Type := "Fungi"], 
  bac_alpha[, Type := "Bacteria"]
)

# fun_alpha <-  

# Full model
formula <- metric ~ treatment + timepoint + treatment:timepoint + experiment + treatment:experiment + (year + 1 | plot / experiment) + (1 | block / experiment)

# Timepoint model for E1
formula_t <- metric ~ treatment * timepoint + (1 | plot) + (1 | block)

# formula_t <- metric ~ treatment * timepoint + (1 | block / plot)

# Experiment model without timepoint 2
formula_e <- metric ~ treatment * experiment + (1 | block / experiment)


alpha_anova <- function(data, formula, metrics, nperm = 1000) {
  sources <- unique(data$source)
  for (src in sources) {
    data_src <- data[source == src]
    for (met in metrics) {
      data_src[, metric := rank(data_src[[met]])]
      cat("\n", src, ":", met, "\n", sep = "")
      res <- perm.lmer(formula, data_src, type = "anova", nperm = nperm)
      print(res)
    }
  }
}


metrics <- c("S.chao1", "shannon", "simpson")

# Fungi

alpha_anova(
  fun_alpha, formula, metrics, nperm = 1000
)

# Bacteria

alpha_anova(
  bac_alpha, formula, metrics, nperm = 1000
)

```

## Beta diversity

### PCA

```{r pca}

n_pcs <- 10

fun_pca <- des_to_pca(FUN$dds)
# fun_pca <- t(data.frame(t(pca$x) * pca$percentVar))

bac_pca <- des_to_pca(BAC$dds)
# bac_pca <- t(data.frame(t(pca$x) * pca$percentVar))


fun_pca_summary <- apply(
  fun_pca$x[, 1:n_pcs], 2, 
  function(x){
    summary(aov(update(T_DESIGN, x ~ .), data = as.data.frame(cbind(x, colData(FUN$dds)))))
  }
)

fun_pca_summary

bac_pca_summary <- apply(
  bac_pca$x[, 1:n_pcs], 2, 
  function(x){
    summary(aov(update(T_DESIGN, x ~ .), data = as.data.frame(cbind(x, colData(BAC$dds)))))
  }
)

bac_pca_summary


```
