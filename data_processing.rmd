---
title: "Waterlogging microbiome data processing"
author: "Hamish McLean"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: cerulean
    highlight: tango
params:
  pipeline: "DADA2"
---

```{r setup, include=FALSE}

if (!exists("params")) params <- list(pipeline = "DADA2")

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = TRUE)

# Kable options
options(
  browser = "false",
  kableExtra.html.bsTable = TRUE,
  kableExtra.bootstrap_options = c("striped", "hover", "condensed"),
  kableExtra_view_html = interactive(),
  knitr.table.format = "html",
  viewer = NULL # Disable viewer to avoid opening in browser
)

Sys.setenv("BROWSER" = "false")

```

```{r libraries}

library(data.table)
library(DESeq2)
library(dplyr)
library(ggpubr)
library(gridExtra)
library(here)
library(kableExtra)
library(vegan)
library(viridis)

```

```{r functions}

# here <- here::here()

FUNC_DIR <- here("functions")

source(here(FUNC_DIR, "functions.R"))
source(here(FUNC_DIR, "loadme.R"))
source(here(FUNC_DIR, "metabarcoding.R"))
source(here(FUNC_DIR, "metafuncs.R"))
source(here(FUNC_DIR, "rarefaction.R"))

```

```{r constants}

DATA_DIR    <- normalizePath(here("..", "Data"))
FIGURES_DIR <- here("figures")
OBJECT_DIR  <- here("objects")

# Bioinformatics pipeline (defaults to DADA2)
# This should be set in the YAML header or passed as a parameter
PIPELINE    <- params$pipeline # DADA2 or USEARCH
ASV_FILTER  <- 0.001 # ASV filter for removing low abundance ASVs
READ_FILTER <- 0.05  # Read count filter for rarefaction
TAX_CONF    <- 0.65  # Confidence threshold for taxonomic rank assignment
SEED        <- 25647 # Random seed

# Colour blind palette
cbPalette <- c(
  "#000000", "#E69F00", "#56B4E9", "#009E73", 
  "#F0E442", "#0072B2", "#D55E00", "#CC79A7"
)

```

## Load data

Load data from pipeline `r PIPELINE` into data objects.
Cleanup names and columns and set factors.

```{r load data}

# File extensions based on pipeline
if(PIPELINE == "DADA2") {
  asv_ext <- ".asv_table_filtered.txt"
  fun_tax <- "FUN.sintax.taxa"
  bac_tax <- "BAC.sintax.taxa"
} else if(PIPELINE == "USEARCH") {
  asv_ext <- ".zotu_table.txt"
  fun_tax <- "zFUN.sintax.taxa"
  bac_tax <- "zBAC.sintax.taxa"
} else {
  stop("Pipeline not recognised")
}

# Load fungal data

FUN <- loadData(
  here(DATA_DIR, PIPELINE, paste0("FUN", asv_ext)),
  here(DATA_DIR, "metadata.txt"),
  here(DATA_DIR, PIPELINE, fun_tax),
  tax_conf = TAX_CONF,
  RHB = "FUN"
)

# Load bacterial data

BAC <- loadData(
  here(DATA_DIR, PIPELINE, paste0("BAC", asv_ext)),
  here(DATA_DIR, "metadata.txt"),
  here(DATA_DIR, PIPELINE, bac_tax),
  tax_conf = TAX_CONF,
  RHB = "BAC"
)

# Remove ".raw" from the end of the colnames of the countData
colnames(FUN$countData) <- gsub("\\.raw$", "", colnames(FUN$countData))
colnames(BAC$countData) <- gsub("\\.raw$", "", colnames(BAC$countData))

# Add a new column to colData that combines experiment and timepoint
FUN$colData$exp_tp <- paste(FUN$colData$experiment, FUN$colData$timepoint, sep = "|")
BAC$colData$exp_tp <- paste(BAC$colData$experiment, BAC$colData$timepoint, sep = "|")

# Add a new column to colData that combines experiment and block
FUN$colData$e_block <- paste(FUN$colData$experiment, FUN$colData$block, sep = "_")
BAC$colData$e_block <- paste(BAC$colData$experiment, BAC$colData$block, sep = "_")

# Convert all columns to factors
FUN$colData[] <- lapply(FUN$colData, as.factor)
BAC$colData[] <- lapply(BAC$colData, as.factor)

```

## Filter data

### Filter taxa

Plantae taxa are filtered from fungal `taxData`.
Chloroplast and Eukaryote  taxa are filtered from bacterial `taxData`.
Corresponding ASVs are removed from `countData`.

```{r filter taxa}

# Fungi: Plantae ASVs
cat(
  "Fungi:\n",
  " - Total ASVs:", nrow(FUN$taxData), "\n",
  " - Plantae ASVs:", length(grep("Plantae", FUN$taxData$kingdom)), "\n\n"
)

# Filter Plantae ASVs
filt <- rownames(FUN$taxData[grep("Plantae", FUN$taxData$kingdom), ])

if(length(filt) == 0) {
  cat("No fungal ASVs to remove\n")
} else {
  cat("Fungi: removing", length(filt), "ASVs\n")
  FUN$taxData <- FUN$taxData[!rownames(FUN$taxData) %in% filt, ]
  FUN$countData <- FUN$countData[!rownames(FUN$countData) %in% filt, ]
}

# Bacteria: Chloroplast (Streptophyta) and Eukaryote ASVs
cat(
  "Bacteria:\n",
  " - Total ASVs:", nrow(BAC$taxData), "\n",
  " - Chloroplast ASVs:", nrow(BAC$taxData[
    grepl("Streptophyta", BAC$taxData$genus) & 
    as.numeric(BAC$taxData$g_conf) >= TAX_CONF,
  ]), "\n",
  " - Eukaryote ASVs:", length(grep("Eukaryota", BAC$taxData$kingdom)), "\n\n"
)

# Filter Chloroplast and Eukaryote ASVs
filt <- rownames(
  BAC$taxData[
    grepl("Streptophyta", BAC$taxData$genus) & 
    as.numeric(BAC$taxData$g_conf) >= TAX_CONF,
  ]
)

filt <- unique(c(filt, rownames(BAC$taxData[grep("Eukaryota", BAC$taxData$kingdom), ])))

if(length(filt) == 0) {
  cat("No Bacterial ASVs to remove\n")
} else {
  cat("Bacteria: removing", length(filt), "ASVs\n")
  BAC$taxData   <- BAC$taxData[!rownames(BAC$taxData) %in% filt, ]
  BAC$countData <- BAC$countData[!rownames(BAC$countData) %in% filt, ]
}

```

### Rarefaction

Remove samples with read count below `r READ_FILTER * 100` % of median.

```{r rarefaction}

rare_fun <- gfunc(FUN$countData, FUN$colData, "Fungi")

rare_bac <- gfunc(BAC$countData, BAC$colData, "Bacteria")

rarefaction_plots <- grid.arrange(
  rare_bac, rare_fun,
  # left = textGrob(label = expression("log"[10] * " aligned sequences"), rot = 90),
  bottom = "ASV count", nrow = 2
)

ggsave(filename = "rarefaction_plots.png", plot = rarefaction_plots, path = FIGURES_DIR)

# Fungi
med <- median(colSums(FUN$countData))
filt <- !colSums(FUN$countData) > med * READ_FILTER
cat("Fungi: ", sum(filt), "sample(s) with <", READ_FILTER * 100, "% of median reads\n\n")

# Bacteria
med <- median(colSums(BAC$countData))
filt <- !colSums(BAC$countData) > med * READ_FILTER
cat("Bacteria: ", sum(filt), "sample(s) with <", READ_FILTER * 100, "% of median reads\n\n")

```

### Filter ASVs by read count

Remove ASVs with less than `r ASV_FILTER * 100` % of total reads across all samples.

```{r asv propotions}

asv_propotions <- function(countData, proportion){
  i <- sum(countData)
  y <- rowSums(countData)
  y <- y[order(y, decreasing = T)]
  asvs <- length(y[(cumsum(y) / i <= proportion)])
  return(asvs)
}

proportions <- c(0.5, 0.9, 0.99, 0.999, 1)

top_asvs <- data.table(
  "proportion" = proportions,
  "Fungi" = lapply(proportions, function(x) asv_propotions(FUN$countData, x)),
  "Bacteria" = lapply(proportions, function(x) asv_propotions(BAC$countData, x))
)

top_asvs |> printTable()

```

Keep only ASVs with at least 10 reads in at least 2 samples.

```{r filter asvs}

filter_asvs <- function(countData, min_count = 10, min_samples = 2) {
  keep <- rowSums(countData >= min_count) >= min_samples
  names(keep[keep])
}

# Fungi
# keep <- filter_otus(FUN$countData, ASV_FILTER)
keep <- filter_asvs(FUN$countData)
cat(
  "Fungi:\n", 
  " - total ASVs:", nrow(FUN$countData), "\n",
  " - removing", nrow(FUN$countData) - length(keep), "ASVs\n",
  " - remaining ASVs:", length(keep), "\n\n"
)

FUN$taxData <- FUN$taxData[rownames(FUN$taxData) %in% keep,]
FUN$countData <- FUN$countData[rownames(FUN$countData) %in% keep,]

# Bacteria
# keep <-  filter_asvs(BAC$countData, ASV_FILTER)
keep <- filter_asvs(BAC$countData)
cat(
  "Bacteria:\n",
  " - total ASVs:", nrow(BAC$countData), "\n",
  " - removing", nrow(BAC$countData) - length(keep), "ASVs\n",
  " - remaining ASVs:", length(keep), "\n\n"
)

BAC$taxData <- BAC$taxData[rownames(BAC$taxData) %in% keep,]
BAC$countData <- BAC$countData[rownames(BAC$countData) %in% keep,]

```

## Absolute abundance normalisation

ASV normalisation is performed using qPCR theoretical copy number data.
Copy number is calculated per mg of root sample from the qPCR data.

### Prepare qPCR abundance data

```{r qPCR abundance}

abundance <- read.csv(here(DATA_DIR, "abundance.csv"))

FUN$abundance <- subset(abundance, Target == "ITS")
BAC$abundance <- subset(abundance, Target == "16S")

rownames(FUN$abundance) <- FUN$abundance$Sample
rownames(BAC$abundance) <- BAC$abundance$Sample

# Add `copy_number` to colData from abundance data `TCN_mg`
FUN$colData$copy_number <- FUN$abundance[rownames(FUN$colData), "TCN_mg"]
BAC$colData$copy_number <- BAC$abundance[rownames(BAC$colData), "TCN_mg"]

FUN$colData$log10_copy_number <- log10(FUN$colData$copy_number + 1)
BAC$colData$log10_copy_number <- log10(BAC$colData$copy_number + 1)

```

## Subset data

For both fungi and bacteria:
Subset by each question (experiment and timepoint).
Subset by each source (root and soil).

```{r subset data}

make_subsets <- function(data, group_var, sources = c("root", "soil")) {
  out <- list()
  for (src in sources) {
    sample_idx <- data$colData$source == src & data$colData[[group_var]] == 1
    samples    <- rownames(data$colData)[sample_idx]
    asv_idx    <- rowSums(data$countData[, samples]) > 0 # Drop rows of 0s
    asvs       <- rownames(data$countData)[asv_idx]
    out[[src]] <- list(
      colData   = data$colData[samples, ],
      countData = data$countData[asvs, samples],
      taxData   = data$taxData[asvs, ]
    )
  }
  out
}

EXP <- list(
  FUN = make_subsets(FUN, group_var = "timepoint"),
  BAC = make_subsets(BAC, group_var = "timepoint")
)

TIME <- list(
  FUN = make_subsets(FUN, group_var = "experiment"),
  BAC = make_subsets(BAC, group_var = "experiment")
)

```

## Create DESeq objects

DESeq2 objects are created for each subset of data.

Absolute abundance normalisation using DESeq2 size factors calculated from qPCR-derived copy number.

Size factor values are centred around the mean of the copy number.

```{r DESeq}

create_dds <- function(data, name, source, design = ~ 1) {
  if(identical(colnames(data$countData), rownames(data$colData))) {

    # Create DESeq object
    dds <- DESeqDataSetFromMatrix(
      countData = data$countData,
      colData = data$colData,
      design = design
    )

    # Set size factors based on copy number
    sizeFactors(dds) <- data$colData$copy_number / mean(data$colData$copy_number)
    # Add dds to data list
    data$dds <- dds
    return(data)

    print(paste0(name, ": ", source, " DESeq object created"))
  } else {
    stop(paste0(name, ": ", source, " countData and colData do not match"))
    next
  }
}

# EXP$FUN  <- apply_to_subsets(EXP$FUN, create_dds)
# TIME$FUN <- apply_to_subsets(TIME$FUN, create_dds)

# EXP$BAC  <- apply_to_subsets(EXP$BAC, create_dds)
# TIME$BAC <- apply_to_subsets(TIME$BAC, create_dds)

EXP <- apply_to_subsets(EXP, create_dds)
TIME <- apply_to_subsets(TIME, create_dds)

```

## Export data objects

```{r export objects}

saveRDS(FUN, here(OBJECT_DIR, "FUN.rds"))
saveRDS(BAC, here(OBJECT_DIR, "BAC.rds"))
saveRDS(EXP, here(OBJECT_DIR, "EXP.rds"))
saveRDS(TIME, here(OBJECT_DIR, "TIME.rds"))
# saveRDS(EXP$FUN, here(OBJECT_DIR, "EXP$FUN.rds"))
# saveRDS(EXP$BAC, here(OBJECT_DIR, "EXP$BAC.rds"))
# saveRDS(TIME$FUN, here(OBJECT_DIR, "TIME$FUN.rds"))
# saveRDS(TIME$BAC, here(OBJECT_DIR, "TIME$BAC.rds"))

```

## ASV and sample summary

### Read and sample summary

```{r read summary}

#' @title Read summary
#' @description Create a summary of the read counts per sample
#' @param dds DESeq2 object
#' @param norm Logical, whether to normalise the counts
#' @return A data.table with the total, mean, median, max and min reads per sample
#'
read_summary <- function(dds, norm = FALSE) {
  countData <- counts(dds, normalize = norm)
  data.table(
    "Total reads" = sum(countData),
    "Mean reads per sample" = mean(colSums(countData)),
    "Median reads per sample" = median(colSums(countData)),
    "Max reads per sample" = max(colSums(countData)),
    "Min reads per sample" = min(colSums(countData))
  )
}

print_read_summary <- function(data, title) {
  cat("\n", title, "\n")
  data.table(
    "Metric" = c(
      "Total reads", "Mean reads per sample", "Median reads per sample", 
      "Max reads per sample", "Min reads per sample"
    ),
    "Root (Raw)" = unlist(read_summary(data$root$dds, FALSE)),
    "Root (Normalized)" = unlist(read_summary(data$root$dds, TRUE)),
    "Soil (Raw)" = unlist(read_summary(data$soil$dds, FALSE)),
    "Soil (Normalized)" = unlist(read_summary(data$soil$dds, TRUE))
  ) #%>%
    # kbl() %>%
    # kable_styling("striped", full_width = F)
}

print_read_summary(EXP$FUN, "Fungi Experiment Read Summary") |> printTable()
print_read_summary(TIME$FUN, "Fungi Timepoint Read Summary") |> printTable()
print_read_summary(EXP$BAC, "Bacteria Experiment Read Summary") |> printTable()
print_read_summary(TIME$BAC, "Bacteria Timepoint Read Summary") |> printTable()

```

### ASV summary 

```{r asv summary}

#' @title ASV summary
#' @description Create a summary of the read counts per ASV
#' @param dds DESeq2 object
#' @param norm Logical, whether to normalise the counts
#' @return A data.table with the total, mean, median, max and min reads per ASV
#'
asv_summary <- function(dds, norm = FALSE) {
  countData <- counts(dds, normalize = norm)
  data.table(
    "Total ASVs" = nrow(countData),
    "Mean reads per ASV" = round(mean(rowSums(countData)), 1),
    "Median reads per ASV" = median(rowSums(countData)),
    "Max reads per ASV" = max(rowSums(countData)),
    "Min reads per ASV" = min(rowSums(countData))
  )
}

print_asv_summary <- function(data, title) {
  cat("\n", title, "\n")
  data.table(
    "Metric" = c(
      "Total ASVs", "Mean reads per ASV", "Median reads per ASV", 
      "Max reads per ASV", "Min reads per ASV"
    ),
    "Root (Raw)" = unlist(asv_summary(data$root$dds, FALSE)),
    "Root (Normalized)" = unlist(asv_summary(data$root$dds, TRUE)),
    "Soil (Raw)" = unlist(asv_summary(data$soil$dds, FALSE)),
    "Soil (Normalized)" = round(unlist(asv_summary(data$soil$dds, TRUE)), 2)
  )
}

print_asv_summary(EXP$FUN, "Fungi Experiment ASV Summary") |> printTable()


data.table(
  "Metric" = c(
    "Total ASVs", "Mean reads per ASV", "Median reads per ASV", 
    "Max reads per ASV", "Min reads per ASV"
  ),
  "Fungi (Raw)" = unlist(asv_summary(FUN$dds, FALSE)),
  "Fungi (Normalized)" = unlist(asv_summary(FUN$dds, TRUE)),
  "Bacteria (Raw)" = unlist(asv_summary(BAC$dds, FALSE)),
  "Bacteria (Normalized)" = round(unlist(asv_summary(BAC$dds, TRUE)), 2)
) %>%
  kbl() %>%
  kable_styling("striped", full_width = F)


top_asvs <- function(countData, taxData, n = 10) {
  y <- rowSums(countData)
  y <- y[order(y, decreasing = T)]
  xy <- y / sum(y)
  data.frame(
    counts = y[1:n], 
    proportion = xy[1:n], 
    rank = taxData[names(y)[1:n],]$rank
  )
}

top_asvs(FUN$countData, FUN$taxData, n = 10)

top_asvs(counts(BAC$dds, normalize = TRUE), BAC$taxData, n = 10)

```

## Taxonomy Summary

### Taxonomy identifiable

Proportion of ASVs which can be assigned (with the given confidence) at each taxonomic rank.

```{r taxonomy ASVs}

taxonomy_summary <- function(taxData) {
  tx <- copy(taxData)
  setDT(tx)
  cols <- names(taxData)[9:15]
  tx[, (cols) := lapply(.SD, as.numeric), .SDcols = cols]
  
  data.table(
    rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
    "0.8" = round(unlist(lapply(cols, function(col) sum(tx[[col]] >= 0.8) / nrow(tx))), 2),
    "0.65" = round(unlist(lapply(cols, function(col) sum(tx[[col]] >= 0.65) / nrow(tx))), 2),
    "0.5" = round(unlist(lapply(cols, function(col) sum(tx[[col]] >= 0.5) / nrow(tx))), 2)
  )
}

# Fungi

taxonomy_summary(FUN$taxData) %>%
  kbl() %>%
  kable_styling("striped", full_width = F)

# Bacteria

taxonomy_summary(BAC$taxData) %>%
  kbl() %>%
  kable_styling("striped", full_width = F)

```

Proportion of reads which can be assigned to each taxonomic rank.

```{r taxonomy reads}

taxonomy_summary_reads <- function(taxData, dds) {
  tx <-taxData[rownames(dds), ]
  nc <- counts(dds, normalize = T)
  ac <- sum(nc)
  cols <- names(tx)[9:15]
  # tx[, (cols) := lapply(.SD, as.factor), .SDcols = cols]

  data.table(
    rank = c("kingdom", "phylum", "class", "order", "family", "genus", "species"),
    "0.8" = round(unlist(lapply(cols, function(col) sum(nc[which(as.numeric(tx[[col]]) >= 0.8),]) / ac)), 2),
    "0.65" = round(unlist(lapply(cols, function(col) sum(nc[which(as.numeric(tx[[col]]) >= 0.65),]) / ac)), 2),
    "0.5" = round(unlist(lapply(cols, function(col) sum(nc[which(as.numeric(tx[[col]]) >= 0.5),]) / ac)), 2)
  )
}

# Fungi

# taxonomy_summary_reads(FUN$taxData, FUN$dds) %>%
#   kbl() %>%
#   kable_styling("striped", full_width = F)

# Bacteria

taxonomy_summary_reads(BAC$taxData, BAC$dds) %>%
  kbl() %>%
  kable_styling("striped", full_width = F)

```

### Taxonomy plots

```{r taxonomy plots}

```
