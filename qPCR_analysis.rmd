---
title: "Waterlogging qPCR Analysis"
output: 
  html_document:
    mathjax: default
    df_print: kable
    highlight: haddock
---

## Overview

Load qPCR data from csv files exported from the qPCR machine.
Separate the qPCR data into samples, standards, and NTCs.
Remove outliers from the triplicates based on a standard deviation threshold 
and maximum $C_q$ value.
Calculate standard curves for the standards on each plate.
Calculate efficiency of each qPCR reactions.

## Setup

```{r libraries, include = FALSE}

library(data.table)
library(ggpubr)
library(here)
library(kableExtra)
library(knitr)
library(latex2exp)
library(rmarkdown)

```

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

# Kable options
options(
  knitr.table.format = "html",
  kableExtra.html.bsTable = TRUE,
  kableExtra.bootstrap_options = c("striped", "hover", "condensed")
)

```

```{r variables}

cq_threshold <- 0.5 # Threshold for difference between triplicate Cq values
max_cq       <- 35 # Maximum Cq value to keep

here         <- here::here() # Set working directory to location of this file
data_dir     <- file.path(here, "..", "Data") |> normalizePath() # Data
fig_dir      <- file.path(here, "figures", "qPCR") # Figures

```

```{r functions}

kbl <- function(...) {
  kable(...) |> kable_styling()
}

```

## Load qPCR Data

Load qPCR data from csv files exported from the qPCR machine.
Store data from each plate in a list containing data.tables for samples, 
standards, and NTCs.

```{r data}

#' Load qPCR data from a csv file
#' @param file_path The path to the csv file
#' @param header_rows The number of header rows to skip
#' @param columns The columns to select
#' @return A list containing the samples, standards, and NTCs as data.tables
#'
load_qpcr_data <- function(file_path, header_rows = 19, columns = data_cols) {


  # Read the csv file and skip the header rows
  data <- fread(
    file = file_path, skip = header_rows, select = columns,
    na.strings = c("", "NA", "NaN", "None"), fill = TRUE
  )
  setnames(data, "Starting Quantity (SQ)", "Concentration")

  # Get plate number from file name
  # Add plate number to the data
  plate <- as.numeric(gsub(".* plate (\\d+).*", "\\1", basename(file_path)))
  data[, Plate := plate]

  # Rename Content values
  data[, Content := fcase(
    startsWith(Content, "Unkn"), "Sample",
    startsWith(Content, "Std"), "Standard",
    startsWith(Content, "NTC"), "NTC"
  )]

  # Add Type column based on Content
  data[Content == "Sample", Type := fcase(
    Sample %in% unlist(roots), "Root",
    Sample %in% unlist(soil), "Soil"
  )]
  data[Content == "Standard", Type := fcase(
    startsWith(Sample, "Sr"), "Root",
    startsWith(Sample, "Ss"), "Soil"
  )]

  # Add leading 0 to samples for sorting
  data[Content == "Sample", Sample := sprintf("%02d", as.numeric(Sample))]

  # Calculate sample concentration
  data[, Dilution := as.numeric(Dilution)]
  data[Content == "Sample", Concentration := 1 / as.numeric(Dilution)]
  data[Content == "Standard", Dilution := 1 / as.numeric(Concentration)]
  data[, log10_concentration := log10(Concentration)]

  # Construct the plate object
  list(
    plate     = plate,
    data 	 	  = data,
    samples   = data[Content == "Sample"],
    standards = data[Content == "Standard"],
    ntcs      = data[Content == "NTC"]
  )

}


# Define the columns to select from the csv file
data_cols <- c(
  "Well", "Target", "Content", "Replicate", "Sample", "Dilution",
  "Cq", "Starting Quantity (SQ)"
)


# Define the plate files
plate_files <- list(
  plate_1 = file.path(data_dir, "qPCR", "2025-02-26 plate 1 roots ITS.csv"),
  plate_2 = file.path(data_dir, "qPCR", "2025-03-06 plate 2 roots 16S.csv"),
  plate_3 = file.path(data_dir, "qPCR", "2025-03-10 plate 3 soil ITS.csv"),
  plate_4 = file.path(data_dir, "qPCR", "2025-03-17 plate 4 soil 16S.csv"),
  plate_5 = file.path(data_dir, "qPCR", "2025-06-17 plate 5 repeats.csv")
)


# Define sample sources
roots <- list(01:10, 21:30, 41:50)
soil  <- list(11:20, 31:40, 51:60)


# Load qPCR data from csv files
# Use suppressWarnings to ignore warnings about missing values in Cq
# This is expected for NTCs and some samples with no amplification
plates <- suppressWarnings(lapply(plate_files, load_qpcr_data))

```

## Remove triplicate outliers

Remove outliers with $\Delta C_q >$ `r cq_threshold` between each triplicate and the median.
Samples above a maximum $C_q$ value of `r max_cq` are also removed.
If only a single replicate from a triplicate remains, the sample is removed and 
the corresponding sample from the other dilution is also removed because 
efficiency cannot be calculated.

Removed outliers are returned.

```{r flag_outliers, results = "asis"}

#' Flag outliers from a qPCR plate with Cq standard deviation > threshold
#' or the Cq value above a maximum value or na Cq values.
#' If only a single replicate from a triplicate remains, the sample is flagged.
#' Corresponding samples from the other dilution are also flagged.
#' @param data A data.table containing qPCR data
#' @param threshold The standard deviation threshold
#' @param max_cq The maximum Cq value to keep
#' @return The data.table with a column "Outlier" containing the flag
#'
flag_outliers <- function(data, threshold = cq_threshold, cq_max = max_cq) {
  outliers <- copy(data)

  # Group by replicate and flag outliers
  outliers[,
    Outlier := fcase(
      abs(Cq - median(Cq)) > threshold, "outlier",
      Cq > cq_max, "high Cq",
      is.na(Cq), "missing Cq",
      default = "ok"
    ),
    by = .(Target, Content, Replicate)
  ]

  # Remove singletons
  outliers[,
    Outlier := ifelse(
      Outlier == "ok" & sum(Outlier == "ok") == 1,
      "singleton", Outlier
    ),
    by = .(Target, Content, Replicate)
  ]

  # Remove corresponding samples from other dilutions
  outliers[,
    Outlier := ifelse(
      Outlier == "ok" & sum(Outlier == "ok") <= .N / 2,
      "insufficient data", Outlier
    ),
    by = .(Target, Content, Sample)
  ]

  return(outliers)
}


# Flag outliers
plates <- lapply(plates, function(plate) {
  plate$data <- flag_outliers(plate$data)
  plate
})


# Remove outliers
plates <- lapply(plates, function(plate) {
  plate$samples   <- plate$data[Content == "Sample"   & Outlier == "ok"]
  plate$standards <- plate$data[Content == "Standard" & Outlier == "ok"]
  plate
})

# kbl(
#   plates$plate_1$data[Outlier != "ok"][order(Sample)],
#   caption = "Plate 1 outliers", digits = 2
# )

# Print outliers
lapply(plates, function(plate) {
  print(kbl(
    plate$data[Outlier != "ok"][order(Sample)],
    caption = paste("Plate", plate$plate, "outliers"),
    digits = 2
  ))
  cat("<br><br>\n")
})

# for(plate in plates) {
#   print(kbl(
#     plate$data[Outlier != "ok"][order(Sample)],
#     caption = paste("Plate", plate$plate, "outliers"),
#     digits = 2
#   ))
# }

```

## Efficiency

Fit a linear model to $C_q \sim \log_{10}(concentration)$ for each sample in a qPCR plate.
Calculate PCR efficiency based on the equation 
$$E = 10^{-1/slope}$$
where $slope$ is the slope of the linear model.
Perfect efficiency is 2.

```{r efficiency}

#' Calculate the efficiency of a qPCR reaction based on the equation
#' \deqn{E = 10^{-1/slope}}
#' @param slope The slope between the Cq and log10 concentration
#' @return The efficiency of the qPCR reaction
#'
efficiency <- function(slope) {
  10^(-1 / slope)
}


#' Calculate summary statistics for each sample in a qPCR plate
#' @param data A data.table containing qPCR data
#' @return A data.table containing the summary statistics
#'
calculate_summary_statistics <- function(data) {
  data[,
    {
      model <- lm(Cq ~ log10(Concentration))
      intercept <- model$coefficients[1]
      slope <- model$coefficients[2]
      list(
        Target     = Target[1],
        N          = .N,
        Intercept  = intercept,
        Slope      = slope,
        R2         = summary(model)$r.squared,
        Efficiency = efficiency(slope)
      )
    },
    by = Sample
  ][order(as.numeric(Sample))]
}


# Calculate summary statistics
plates <- lapply(plates, function(plate) {
  plate$stats <- calculate_summary_statistics(plate$samples)
  plate
})


# Print summary statistics
for (plate in plates) {
  kbl(plate$stats, caption = paste("Plate", plate$plate, "summary"), digits = 2)
}


# Add stats to samples
plates <- lapply(plates, function(plate) {
  plate$samples <- merge(plate$samples, plate$stats, by = c("Sample", "Target"))
  plate
})

```

### Efficiency adjusted $C_q$

$C_q$ can be adjusted for efficiency by the equation:

$$
C_{q, adjusted}=\log_{2}\!\left(E^{C_{q}}\right)
$$

Where $E$ is the PCR efficiency of the sample.

To calculate adjusted copy number, a new standard curve is fit to the adjusted $C_q$ values of the standards.

```{r efficiency_adjustment}

#' Calculate the efficiency adjusted Cq values using the equation
#' \deqn{C_{q, adjusted}=\log_{2}\!\left(E^{C_{q}}\right)}
#' @param data A data.table containing qPCR data
#' @return A data.table containing the efficiency adjusted Cq values
#'
efficiency_adjustment <- function(data) {
  data[, Cq_adjusted := ifelse(Efficiency < 2, log2(Efficiency ^ Cq), Cq)]
}


# Calculate efficiency adjusted Cq values
plates <- lapply(plates, function(plate) {
  efficiency_adjustment(plate$samples)
  plate
})

```

## Standard curves

Calculate the standard curve for each qPCR plate.
The standard curve is calculated by fitting a linear model to
$C_q \sim \log_{10} (concentration)$.

```{r standard_curve}

# Remove dilutions < 10^-5 from standards
plates <- lapply(plates, function(plate) {
  plate$standards <- plate$standards[Concentration > 1e-5]
  plate
})


#' Calculate the standard curve for a qPCR plate
#' @param data A data.table containing qPCR standard curve data
#' @return A list containing the intercept, slope, R^2, and efficiency
#'
calculate_standard_curve <- function(data, adjust_cq = FALSE, use_tcn = FALSE) {
  data[, {
    formula <- if (adjust_cq) {
      if (use_tcn) Cq_adjusted ~ log10_TCN else Cq_adjusted ~ log10_concentration
    } else {
      if (use_tcn) Cq ~ log10_TCN else Cq ~ log10_concentration
    }
    model <- lm(formula, data = .SD)
    intercept  <- model$coefficients[1]
    slope      <- model$coefficients[2]
    r_squared  <- summary(model)$r.squared
    efficiency <- efficiency(slope)
    list(
      Plate      = Plate[1],
      N          = .N,
      Intercept  = intercept,
      Slope      = slope,
      R2         = r_squared,
      Efficiency = efficiency
    )
  }, by = .(Target, Type)]
}


# Calculate standard curves
plates <- lapply(plates, function(plate) {
  plate$standard_curve <- calculate_standard_curve(plate$standards)
  plate
})


# Print standard curves
for (plate in plates) {
  kbl(
    plate$standard_curve, digits = 2, 
    caption = paste("Plate", plate$plate, "standard curve")
  )
}

```

### Standard efficiency adjusted $C_q$

```{r standard_efficiency_adjustment}

# Merge efficiency with standards
plates <- lapply(plates, function(plate) {
  plate$standards <- plate$standards[plate$standard_curve, on = .(Target, Type, Plate)]
  plate
})


# Calculate efficiency adjusted Cq values for standards
plates <- lapply(plates, function(plate) {
  efficiency_adjustment(plate$standards)
  plate
})

```

### Standard curve plots

```{r standard_curve_plots}

#' Plot standard curve
plot_standard_curve <- function(data, standard_curve, name = NULL) {
  targets <- unique(data$Target)
  types <- unique(data$Type)
  plots <- list()
  i <- 1
  for (target in targets) {
    for (type in types) {
      subset_data <- data[Target == target & Type == type]
      if (nrow(subset_data) > 0) {
        plots[[i]] <- ggscatter(
          subset_data, x = "log10_concentration", y = "Cq",
          add = "reg.line", conf.int = TRUE
        ) +
          stat_regline_equation(
            aes(label = paste(
              after_stat(eq.label), after_stat(rr.label), sep = "~~~~"
            )),
            label.x = -2.5, label.y = 32
          ) +
          ggtitle(paste0(
            "Plate ", subset_data$Plate[1], " ", type, " ", target
          )) +
          xlab(TeX("$\\log_{10}(Concentration)$")) +
          ylab(TeX("$C_q$"))
        i <- i + 1
      }
    }
  }
  plot <- ggarrange(plotlist = plots)
  filename <- if (!is.null(name)) name else paste0("plate_", data$Plate[1], "_standard_curve.png")
  ggsave(
    plot = plot, path = fig_dir, width = 8, height = 6,
    filename = filename
  )
  plot
}


for (plate in plates) {
  plot_standard_curve(plate$standards, plate$standard_curve)
}

```

```{r combined_standard_curve}

combined_standard <- rbindlist(lapply(plates, function(plate) plate$standards))

combined_standard_curve <- calculate_standard_curve(combined_standard)

kbl(combined_standard_curve, digits = 2)

plot_standard_curve(
  combined_standard, combined_standard_curve,
  name = "combined_standard_curves.png"
)

combined_standard[Target == "ITS" & Type == "Soil" & Dilution == 1000]

bac_initial_copies <- 1e7
fun_initial_copies <- 1e5

# Add TCN to combined standard from dilution range from initial copies based on concentration of standards
combined_standard[Target == "ITS", TCN := Concentration * fun_initial_copies]
combined_standard[Target == "16S", TCN := Concentration * bac_initial_copies]
combined_standard[, log10_TCN := log10(TCN)]

# Plot TCN vs Cq
ggscatter(
  combined_standard, x = "log10_TCN", y = "Cq_adjusted",
  add = "reg.line", conf.int = TRUE
) +
  stat_regline_equation(
    aes(label = paste(
      after_stat(eq.label), after_stat(rr.label), sep = "~~~~"
    )),
    label.x = 2, label.y = 15
  ) +
  facet_grid(Target ~ Type, scales = "free") +
  ggtitle("Combined Standard Curve") +
  xlab(TeX("$\\log_{10}(TCN)$")) +
  ylab(TeX("$C_q$"))

ggsave(
  plot = last_plot(), path = fig_dir, width = 8, height = 6,
  filename = "TCN_standards.png"
)

# Plot TCN vs Cq_adjusted for each combination of Target and Type
# ggplot(combined_standard, aes(x = log10(TCN), y = Cq_adjusted)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = TRUE) +
#   stat_regline_equation(
#     aes(label = paste(after_stat(eq.label), after_stat(rr.label), sep = "~~~~")),
#     label.x = 0.5, label.y = 15
#   ) +
#   facet_grid(Target ~ Type, scales = "free") +
#   ggtitle("Combined Standard Curves") +
#   xlab(TeX("$\\log_{10}(TCN)$")) +
#   ylab(TeX("$C_q$"))

```

### Standard curve copy number

```{r standard_copy_number}

# Calculate TCN for standards
plates <- lapply(plates, function(plate) {
  plate$standards[Target == "ITS", TCN := Concentration * fun_initial_copies]
  plate$standards[Target == "16S", TCN := Concentration * bac_initial_copies]
  plate$standards[, log10_TCN := log10(TCN)]
  plate
})


# Calculate standard curves for each plate using TCN
plates <- lapply(plates, function(plate) {
  plate$tcn_standard_curve <- calculate_standard_curve(
    plate$standards, adjust_cq = TRUE, use_tcn = TRUE
  )
  plate
})


# Print TCN standard curves
for (plate in plates) {
  kbl(
    plate$tcn_standard_curve, digits = 2,
    caption = paste("Plate", plate$plate, "TCN standard curve")
  )
}

```

## Repeats

Repeat plate 3 soil ITS due to poor soil standard curve.

```{r repeats}

# Print samples in which all reps have been flagged as outliers
repeats <- function(data) {
  data[
    Content == "Sample",
    .SD[all(Outlier != "ok")],
    by = .(Sample, Target)
  ][
    , .(Plate, Type, Target, Sample, Outlier = "outliers")
  ][
    , .SD[1], by = .(Sample, Target)
  ][
    order(Sample)
  ]
}


for (plate in plates) {
  kbl(
    repeats(plate$samples),
    caption = paste("Plate", plate$plate, "repeats"),
    digits = 2
  )
}

```

## Sample copy number

Calculate the theoretical copy number (TCN) of each sample based on the standard curve using the equation:

$$
dilution \times 10^{(C_{q} - intercept)/slope}
$$

```{r sample_copy_number}

#` Calculate TCN for samples
calculate_tcn <- function(data, standard_curve) {
  data[
    standard_curve,
    on = .(Target, Type),
    TCN := Dilution * 10 ^ ((Cq_adjusted - i.Intercept) / i.Slope)
  ]
}


plates <- lapply(plates, function(plate) {
  calculate_tcn(plate$samples, plate$standard_curve)
  plate
})

```

## Sample summary

Calculate the mean and standard deviation of the TCN for each sample.

```{r sample_summary}

#' Calculate sample summary statistics
sample_summary <- function(data) {
  data[
    Content == "Sample",
    .(Mean = mean(TCN), SD = sd(TCN), N = .N),
    by = .(Sample, Target)
  ][
    order(Sample)
  ]
}


plates <- lapply(plates, function(plate) {
  plate$samples_summary <- sample_summary(plate$samples)
  plate
})


ggplot(plates$plate_2$samples, aes(x = Sample, y = log10(TCN))) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5) +
  ggtitle("Sample TCN") +
  xlab("Sample") +
  ylab("TCN") +
  theme("ggpubr")

```

## Combined data

```{r combined_data}

combined_data <- rbindlist(lapply(plates, function(plate) plate$samples))

```

## Repeats

```{r z_score}

# Calculate z score for each replicate
combined_data[, z_score := (TCN - mean(TCN)) / sd(TCN), by = .(Sample, Target)]

combined_data[, z_score := scale(TCN), by = .(Sample, Target)]

combined_data[abs(z_score) > 1.5][order(Target, Sample)]

ggplot(combined_data, aes(x = Sample, y = log10(TCN))) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5) +
  facet_wrap(~ Target, ncol = 1) +
  ggtitle("Sample TCN") +
  xlab("Sample") +
  ylab("TCN") +
  theme("ggpubr")

ggsave(
  plot = last_plot(), path = fig_dir, width = 8, height = 6,
  filename = "combined_sample_tcn.png"
)

ggscatter(
  combined_data[, Plate := factor(Plate)], 
  x = "Sample", y = "Efficiency", color = "Plate"
) + 
  facet_wrap(~ Target, ncol = 1) +
  ggtitle("Sample Efficiency")

ggsave(
  plot = last_plot(), path = fig_dir, width = 8, height = 6,
  filename = "combined_sample_efficiency.png"
)

```

## Summary

Calculate the mean and standard deviation of the TCN for each sample.

Calculate TCN per mg of sample. 2 % of the sample mass was used for DNA extraction.

```{r summary}

summary <- combined_data[,
  .(mean_TCN = mean(TCN), sd_TCN = sd(TCN), N = .N),
  by = .(Target, Sample)
]

# Combined with sample mass
sample_mass <- fread(file.path(data_dir, "qPCR", "sample_mass.csv"))[, Sample := sprintf("%02d", Sample)]
summary <- merge(summary, sample_mass, by = "Sample")

summary[, TCN_mg := mean_TCN / (mg * 2 / 100)]

kbl(summary)

# Export as csv
fwrite(summary, file.path(data_dir, "abundance.csv"))

```
